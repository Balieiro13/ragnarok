#DB query embedding model
EMBEDDING_MODEL_NAME="all-MiniLM-L6-v2"
EMBEDDING_DEVICE="cpu" #use 'cuda' if you have a nvidia gpu

# LLM
LLM_SERVER="https://abps.ink/llm/"
OPENAI_API_KEY="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"
OPENAI_API_MODEL="gpt-3.5-turbo"

# If you choose to run your own docker container 
# with chromadb, use the following env keys:
DB_HOST="localhost"
DB_PORT="8000"
