# If you choose to run your own docker container 
# with chromadb, use the following env keys:
DB_HOST="localhost"
DB_PORT="8000"

#DB query embedding model
# EMBEDDING_MODEL_NAME="all-MiniLM-L6-v2"
EMBEDDING_MODEL_NAME="BAAI/bge-large-en-v1.5"
EMBEDDING_DEVICE="cuda" #use 'cuda' if you have a nvidia gpu

# LLM
LLM_SERVER="https://abps.ink/llm/"
HF_MODEL="TheBloke/Mistral-7B-OpenOrca-GPTQ"
# HF_MODEL="Open-Orca/Mistral-7B-OpenOrca"
# HF_MODEL="TheBloke/OpenOrca-Platypus2-13B-GPTQ"
# HF_MODEL="TheBloke/Llama-2-13B-chat-GPTQ"
OPENAI_API_KEY="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"
# OPENAI_API_MODEL="gpt-3.5-turbo-16k"
OPENAI_API_MODEL="gpt-4"

# LLM ARGS
TEMPERATURE="0.8"
MAX_NEW_TOKENS="512"
